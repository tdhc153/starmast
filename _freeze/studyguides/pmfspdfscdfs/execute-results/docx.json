{
  "hash": "14eb31c95fc356b85bf881d0c4741818",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: PMFs, PDFs, and CDFs\nauthor: Sophie Chowgule\nabstract-title: Summary\nabstract: Probability mass functions (PMFs), probability density functions (PDFs), and cumulative distribution functions (CDFs) are fundamental concepts in statistics. These functions describe how probabilities are distributed across the possible outcomes of random events. PMFs, PDFs, and CDFs are commonly used to model probability distributions, helping to visualize and understand the behaviour of random processes. This guide will explore the role of each function, how they differ, and highlight their applications.\ncategories:\n  - Probability\n  - Statistics\nfilters:\n  - shinylive\n---\n\n\n\n\n\n\n\n\n\n\n*Before reading this guide, it is highly recommended that you read [Guide: Introduction to probability](introtoprobability.qmd), [Guide: Discrete random variables versus continuous random variables], and [Guide: Introduction to integration].*\n\n::: {.content-visible when-format=\"html\"}\n\n\n\n\n\n\n\n\n```{=html}\n<table><tr><td style=\"vertical-align: middle\"><strong>Narration of study guide:</strong>&nbsp;&nbsp;</td><td><audio controls><source src=\"./Narrations/pmfspdfscdfs.mp3\" type=\"audio/mpeg\">Your browser does not support the audio element.</audio></tr></table>\n```\n\n\n\n\n\n\n\n\n:::\n\n# Introduction\n\nPMFs, PDFs, and CDFs are key tools in the study of probability, used to model and analyze the behaviour of random variables. These functions describe how probabilities are distributed across the possible outcomes of random events. In turn, a probability distribution provides a complete description of how these probabilities are assigned to all the possible values of a random variable, whether discrete or continuous. Understanding these functions is important for analyzing data, making predictions, and applying statistical methods to solve real-world problems.\n\n# What is a probability mass function (PMF)?\n\nAs you have seen in [Fact sheet: Discrete random variables versus continuous random variables], a discrete random variable can take on a countable number of distinct outcomes. For example, rolling a fair six-sided die can result in only one of six possible outcomes. A **probability mass function (PMF)** assigns probabilities to each individual outcome of a discrete random variable, helping to determine the chance of a specific event occurring. In the case of the fair six-sided die, the PMF assigns a probability of $1/6$ to each outcome, reflecting that each outcome is equally likely. When applied to the entire discrete random variable, a PMF describes how the total probability is distributed across all possible outcomes. More formally:\n\n::: {.callout-note icon=\"true\"}\n## Definition of a PMF\n\nA **probability mass function** or **PMF** is a function $p(x)$ that, when applied to a discrete random variable $X$, returns the probability $\\mathbb{P}(X=x)$ that $X$ is equal to a specific value $x$. The PMF can be expressed as:\n\n$$\np(x) = \\mathbb{P}(X = x)\n$$\n\nwhere $\\mathbb{P}(X = x)$ is the probability that $X$ equals $x$.\n:::\n\nFor a PMF to be considered a valid probability distribution for a random variable, it must satisfy two conditions:\n\n-  **Non-negativity**: The probability assigned to each possible outcome must be greater than or equal to zero, that is:\n\n$$p(x) = \\mathbb{P}(X = x) \\geq 0\\textsf{ for all values of }x.$$\n\n-  **Honesty condition**: The sum of probabilities of all possible outcomes $x$ of a discrete random variable $X$ must be equal to one: $$\\sum_{x} p(x) = \\sum_{x} \\mathbb{P}(X = x) = 1.$$\n\n::: {.callout-tip}\n\nThe symbol $\\sum$ is called **sigma notation** and represents the sum of all values in a particular set. In this example, it is adding the probabilities from all possible outcomes of a random variable $X$. For more examples, see [Guide: Introduction to sigma notation.](sigmanotation.qmd)\n\n:::\n\n::: {.callout-tip}\nThese conditions follow from the **laws of probability**. For more, see [Guide: Introduction to probability].\n:::\n\n::: {.callout-note appearance=\"simple\"}\n\n## Example 1\n\nYou are given a fair six-sided die. Let the discrete random variable $X$ represent the result of rolling the die, and $x$ represent the six possible outcomes: $1, 2, 3, 4, 5,$ and $6$. Since the die is fair, each outcome has an equal probability of $1/6$. So the PMF $p(x)$ for this scenario is given by:\n\n\n| $x$ | 1 | 2 | 3 | 4 | 5 | 6 |\n|--------|----|----|----|----|----|----|\n| $\\mathbb{P}(X = x)$ | $\\dfrac{1}{6}$ | $\\dfrac{1}{6}$ | $\\dfrac{1}{6}$ | $\\dfrac{1}{6}$ | $\\dfrac{1}{6}$ | $\\dfrac{1}{6}$ |\n\nTable 1: PMF of rolling a fair six-sided die as in Example 1.\n\nYou can check that this is a valid PMF:\n\n**Non-negativity**: All $\\mathbb{P}(X = x) = 1/6 \\geq 0$, so each probability is positive, satisfying the non-negativity requirement.\n\n**Honesty**: You can take the sum across all outcomes: $$\\sum_{x} \\mathbb{P}(X = x) = \\dfrac{1}{6} + \\dfrac{1}{6} + \\dfrac{1}{6} + \\dfrac{1}{6} + \\dfrac{1}{6} + \\dfrac{1}{6} = 1$$ confirming that the total probability of the PMF equals $1$, meeting the honesty condition.\n\nSince the PMF satisfies both the non-negativity and honesty conditions, it is a valid PMF which represents the scenario of rolling a fair six-sided die.\n\n:::\n\n::: {.callout-note appearance=\"simple\"}\n\n## Example 2\n\nImagine you flip a fair coin twice. Let the discrete random variable $X$ represent the number of times the coin lands on heads, so the possible outcomes $x$ are $0,1,$ or $2$.\n\nSince the coin is fair, with equal probabilities for both heads ($H$) and tails  ($T$), the probabilities of the number of heads are determined by counting the outcomes with the correct number of heads. The set (**sample space**, see [Guide: Introduction to probability]) of all possible outcomes of flipping a fair coin twice are $\\{HH, TH, HT, TT\\}$.\n\n- The probability of no heads corresponds to one of the four possible outcomes $TT$, so $\\mathbb{P}(X=0) = 1/4$.\n- The probability of one head corresponds to two of the four possible outcomes $HT,TH$, so $\\mathbb{P}(X=1) = 2/4 = 1/2$.\n- The probability of two heads corresponds to one of the four possible outcomes $HH$, so $\\mathbb{P}(X=2) = 1/4$.\n\nSo the PMF $p(x)$ for this scenario is:\n\n| $x$        | 0    | 1   | 2    |\n|--------|----|----|----|\n| $\\mathbb{P}(X = x)$ | 0.25 | 0.5 | 0.25 |\n\nTable 2: PMF for counting the number of heads in two coin flips as in Example 2.\n\nYou can see that this PMF also satisfies both key conditions:\n\n**Non-negativity**: All probabilities are positive, as $\\mathbb{P}(X = x) \\geq 0$ for all values of $x$.\n\n**Honesty**: The sum of probabilities equals $1$: $$\\sum_{x} \\mathbb{P}(X = x) = 0.25 + 0.5 + 0.25 = 1$$\n\nSo, this is a valid PMF representing the number of heads when you flip a fair coin twice.\n\n:::\n\n::: {.callout-note appearance=\"simple\"}\n\n## Example 3\n\nBuilding on Example 2, common example of a PMF is that of the **binomial distribution**. This is a type of PMF used to count the number of successes in a series of trials with only two possible outcomes: a success with probability $p$, or a failure with probability $q = 1 - p$. Here, the random variable $X$ is 'number of successes'. \n\nTake $x$ to be the number of successes in a number $n$ of trials, $p$ is the probability of success in a single trial, and $q = 1 - p$ is the probability of failure. Then the PMF $p(x)$ for a binomial distribution is given by:\n\n$$\nf(x) = \\mathbb{P}(X=x) = \\binom{n}{x} p^x q^{(n-x)} = \\frac{n!}{(n-x)! x!} p^x q^{(n-x)}\n$$ \nBinomial distributions are often used to model real life scenarios, such as the probability of heads occurring in multiple fair coin flips (as in Example 2!). In this example, heads are considered a success and tails a failure. This time imagine flipping a coin $10$ times, where the probability of success (heads) is $0.5 = 1/2$ and the probability of failure (tails) is $1 - 0.5 = 0.5 = 1/2$.\n\nThe power of the binomial PMF above comes from the number of trials. With two coin flips (as in Example 2), there are $4 = 2^2$ outcomes to consider, which you can count. With ten coin flips, there are $2^{10} = 1024$ different outcomes, which is harder to count. The binomial distribution formula takes care of the probability for you. For instance, the probability of flipping a coin ten times (so $n=10$) and getting four heads (so $x = 4$) is:\n\n$$\\mathbb{P}(X=4) = \\binom{10}{4} \\left(\\frac{1}{2}\\right)^4 \\left(\\frac{1}{2}\\right)^{10-4} = 210\\cdot \\left(\\frac{1}{2}\\right)^{10} = \\frac{210}{1024} \\approx 0.205$$\n\n:::\n\n::: {.content-hidden when-format=\"html\"}\n\n@fig-pmfspdfscdfs1 below shows the probability distribution for the number of heads in a trial of ten coin flips.\n\nYou can find that all binomial distributions are valid PMFs: see [Proof sheet: PMFs, PDFs, CDFs](../proofsheets/ps-pmfspdfscdfs.qmd) for more.\n\n::: {#fig-pmfspdfscdfs1}\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](pmfspdfscdfs_files/figure-docx/unnamed-chunk-1-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\nBinomial distribution for ten coin flips as in Example 3.\n\n:::\n\n:::\n\n::: {.content-visible when-format=\"html\"}\n\nYou can use the interactive calculator below to explore the binomial distribution by changing the probability $p$ and the number of trials $n$. This calculator not only helps you work out the PMF of the binomial distribution, but also the CDF (see later in the guide for a definition of this.)\n\n```{shinylive-r}\n#| standalone: true\n#| viewerHeight: 750\n\nlibrary(shiny)\nlibrary(bslib)\nlibrary(ggplot2)\n\nui <- page_fluid(\n  title = \"Binomial distribution calculator\",\n  \n  layout_columns(\n    col_widths = c(4, 8),\n    \n    # Left column - Inputs\n    card(\n      card_header(\"Parameters\"),\n      card_body(\n        numericInput(\"n\", \"Number of trials (n):\", value = 10, min = 1, step = 1),\n        sliderInput(\"p\", \"Probability of success (p):\", min = 0, max = 1, value = 0.5, step = 0.01),\n        hr(),\n        radioButtons(\"prob_type\", \"Probability to Calculate:\",\n                    choices = list(\"P(X ≤ x)\" = \"less\", \n                                  \"P(X ≥ x)\" = \"greater\", \n                                  \"P(x ≤ X ≤ y)\" = \"between\"),\n                    selected = \"less\"),\n        conditionalPanel(\n          condition = \"input.prob_type == 'less' || input.prob_type == 'greater'\",\n          sliderInput(\"x_value\", \"x value:\", min = 0, max = 10, value = 5, step = 1)\n        ),\n        conditionalPanel(\n          condition = \"input.prob_type == 'between'\",\n          sliderInput(\"x_lower\", \"Lower bound (x):\", min = 0, max = 10, value = 3, step = 1),\n          sliderInput(\"x_upper\", \"Upper bound (y):\", min = 0, max = 10, value = 7, step = 1)\n        )\n      )\n    ),\n    \n    # Right column - Plot\n    card(\n      card_header(\"Binomial distribution plot\"),\n      card_body(\n        uiOutput(\"plot_title\"),\n        plotOutput(\"distPlot\", height = \"300px\")\n      )\n    )\n  ),\n  \n  # Bottom row - Results\n  card(\n    card_header(\"Results\"),\n    card_body(\n      textOutput(\"explanation\")\n    )\n  )\n)\n\nserver <- function(input, output, session) {\n  \n  # Update the range of the sliders when n changes\n  observe({\n    updateSliderInput(session, \"x_value\", max = input$n)\n    updateSliderInput(session, \"x_lower\", max = input$n)\n    updateSliderInput(session, \"x_upper\", max = input$n)\n  })\n  \n  # Ensure that x_upper is always greater than or equal to x_lower\n  observe({\n    if (input$x_upper < input$x_lower) {\n      updateSliderInput(session, \"x_upper\", value = input$x_lower)\n    }\n  })\n  \n  # Display the plot title with distribution parameters\n  output$plot_title <- renderUI({\n    title <- sprintf(\"Bin(n = %d, p = %.2f)\", input$n, input$p)\n    tags$h4(title, style = \"text-align: center; margin-bottom: 15px;\")\n  })\n  \n  # Calculate the probability based on user selection\n  probability <- reactive({\n    if (input$prob_type == \"less\") {\n      prob <- pbinom(input$x_value, size = input$n, prob = input$p)\n      explanation <- sprintf(\"P(X ≤ %d) = %.4f or %.2f%%\", \n                            input$x_value, prob, prob * 100)\n      return(list(prob = prob, explanation = explanation, type = \"less\", x = input$x_value))\n      \n    } else if (input$prob_type == \"greater\") {\n      # For P(X ≥ x), we need 1 - P(X < x) = 1 - P(X ≤ x-1)\n      if (input$x_value == 0) {\n        prob <- 1  # P(X ≥ 0) is always 1\n      } else {\n        prob <- 1 - pbinom(input$x_value - 1, size = input$n, prob = input$p)\n      }\n      explanation <- sprintf(\"P(X ≥ %d) = %.4f or %.2f%%\", \n                            input$x_value, prob, prob * 100)\n      return(list(prob = prob, explanation = explanation, type = \"greater\", x = input$x_value))\n      \n    } else if (input$prob_type == \"between\") {\n      if (input$x_lower == input$x_upper) {\n        # Exact probability for a single value\n        prob <- dbinom(input$x_lower, size = input$n, prob = input$p)\n      } else {\n        # P(x_lower ≤ X ≤ x_upper) = P(X ≤ x_upper) - P(X < x_lower) = P(X ≤ x_upper) - P(X ≤ x_lower-1)\n        upper_prob <- pbinom(input$x_upper, size = input$n, prob = input$p)\n        if (input$x_lower == 0) {\n          lower_prob <- 0\n        } else {\n          lower_prob <- pbinom(input$x_lower - 1, size = input$n, prob = input$p)\n        }\n        prob <- upper_prob - lower_prob\n      }\n      explanation <- sprintf(\"P(%d ≤ X ≤ %d) = %.4f or %.2f%%\", \n                            input$x_lower, input$x_upper, prob, prob * 100)\n      return(list(prob = prob, explanation = explanation, type = \"between\", \n                 lower = input$x_lower, upper = input$x_upper))\n    }\n  })\n  \n  # Display an explanation of the calculation\n  output$explanation <- renderText({\n    res <- probability()\n    return(res$explanation)\n  })\n  \n  # Generate the binomial distribution plot\n  output$distPlot <- renderPlot({\n    # Create data frame for plotting\n    x_values <- 0:input$n\n    prob_mass <- dbinom(x_values, size = input$n, prob = input$p)\n    df <- data.frame(x = x_values, probability = prob_mass)\n    \n    # Create base plot\n    p <- ggplot(df, aes(x = x, y = probability)) +\n      geom_col(fill = \"lightgray\", color = \"darkgray\", alpha = 0.7) +\n      labs(x = \"number of successes (X)\", y = \"probability mass function\") +\n      theme_minimal() +\n      theme(panel.grid.minor = element_blank()) +\n      scale_x_continuous(breaks = x_values)\n    \n    # Add shaded area based on selected probability type\n    res <- probability()\n    \n    if (res$type == \"less\") {\n      highlight_x <- 0:res$x\n      highlight_df <- df[df$x %in% highlight_x, ]\n      \n      p <- p + geom_col(data = highlight_df, aes(x = x, y = probability), \n                       fill = \"#3F6BB6\", color = \"darkgray\", alpha = 0.8)\n      \n    } else if (res$type == \"greater\") {\n      highlight_x <- res$x:input$n\n      highlight_df <- df[df$x %in% highlight_x, ]\n      \n      p <- p + geom_col(data = highlight_df, aes(x = x, y = probability), \n                       fill = \"#3F6BB6\", color = \"darkgray\", alpha = 0.8)\n      \n    } else if (res$type == \"between\") {\n      highlight_x <- res$lower:res$upper\n      highlight_df <- df[df$x %in% highlight_x, ]\n      \n      p <- p + geom_col(data = highlight_df, aes(x = x, y = probability), \n                       fill = \"#3F6BB6\", color = \"darkgray\", alpha = 0.8)\n    }\n    \n    return(p)\n  })\n}\n\nshinyApp(ui = ui, server = server)\n```\n\nYou can find that all binomial distributions are valid PMFs: see [Proof sheet: PMFs, PDFs, CDFs](../proofsheets/ps-pmfspdfscdfs.qmd) for more.\n\n:::\n\n\n# What is a probability density function (PDF)?\n\nUnlike discrete random variables, continuous random variables can take on any number of values within a specified range. For instance, a person’s height could be $170$cm, $170.1$cm or $170.000001$cm. Since these values cannot be counted, calculating the probability distribution for continuous random variables requires the use of a **probability density function (PDF)**. \n\nUnlike PMFs, PDFs assign probabilities to intervals rather than to specific values; this is because there are so many values that assigning probabilities to each of them is impossible to do so (see below!) PDFs are therefore key for determining the likelihood of a continuous random variable falling within a given range.\n\nWhen applied over all possible values of a continuous random variable $X$, the PDF $f(x)$ can be represented as a curve that shows the total probability distribution across all possible outcomes. \n\nThe probability $\\mathbb{P}(a\\leq X\\leq b)$ that the random variable $X$ lies within an interval $[a,b]$ is equal to the area under the curve of PDF $f(x)$ between $a$ and $b$ as shown in @fig-pmfspdfscdfs2:\n\n::: {#fig-pmfspdfscdfs2}\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](pmfspdfscdfs_files/figure-docx/unnamed-chunk-2-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\nA PDF for the continuous random variable $X$, where the shaded area represents the probability that $X$ lies between $a$ and $b$.\n\n:::\n\n::: {.callout-note}\n\n## Definition of a PDF\n\nA **probability density function** or **PDF** is a function $f(x)$ that represents the distribution of probabilities across a continuous random variable $X$. The probability that $X$ lies within an interval $[a,b]$ is found by integrating the PDF over that interval: $$\\mathbb{P}(a\\leq X\\leq b)= \\int_{a}^{b} f(x) \\, \\textrm{d}x $$ where $\\mathbb{P}(a\\leq X\\leq b)$ is the probability that $X$ lies between $a$ and $b$.\n\n:::\n\nJust like PMFs, PDFs must satisfy two main conditions to be considered valid:\n\n- **Non-negativity**: The PDF $f(x)$ must be greater than or equal to zero over its entire range of possible values: $$f(x)\\geq 0\\textsf{ for all values of }x.$$\n\n- **Honesty condition**: The area under the entire PDF $f(x)$ must be equal to $1$, so: $$\\int_{-\\infty}^{\\infty} f(x) \\, \\textrm{d}x = 1.$$\n\n::: {.callout-warning}\n\nYou may be wondering why probabilities for continuous random variables are calculated over intervals, not at individual values. This is because PDFs cannot return probabilities at specific values.\n\nThis is because of any continuous random variable with any PDF $f(x)$, working out the probablity $\\mathbb{P}(X=a)$ gives: $$\\mathbb{P}(X=a) = \\mathbb{P}(a\\leq X\\leq a) = \\int_{a}^{a} f(x) \\, \\textrm{d}x = 0$$ by properties of integration. (See [Guide: Properties of integration] for more.)\n\n:::\n\n::: {.callout-note appearance=\"simple\"}\n## Example 4\n\nYou are given $X$ a continuous random variable which is **uniformly distributed** on the interval $[0,1]$. Here, the word **uniformly** means that all values between $0$ and $1$ are equally likely to occur. The PDF for $X$ is given by: \n$$\nf(x) =\\begin{cases} 1 & \\textsf{if } 0 \\leq x \\leq 1 \\\\0 & \\textsf{otherwise} \\end{cases}\n$$\nand a picture can be found in @fig-pmfspdfscdfs3.\n\n::: {#fig-pmfspdfscdfs3}\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](pmfspdfscdfs_files/figure-docx/unnamed-chunk-3-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\nPDF of a uniform distribution between $0$ and $1$ as in Example 4.\n:::\n\nThe formula for a uniform distribution over any interval $[a,b]$ is given by: \n$$\nf(x) =\\begin{cases} \\dfrac{1}{b-a} & \\textsf{if } a \\leq x \\leq b \\\\[0.5em]0 & \\textsf{otherwise} \\end{cases}\n$$\n\nThe choice of probability here is not an accident; it will ensure that the honesty condition holds for any interval $[a,b]$. See [Proof sheet: PMFs, PDFs, CDFs](../proofsheets/ps-pmfspdfscdfs.qmd) for more.\n\nTo find the probability that $X$ lies between $0.25$ and $0.5$, you can calculate the area under the curve of the PDF within the interval: $$\\int_{0.25}^{0.5} f(x) \\, \\textrm{d}x = \\int_{0.25}^{0.5} 1 \\, \\textrm{d}x = \\big[\\,x\\,\\big]_{0.25}^{0.5} = 0.5 - 0.25 = 0.25$$ Therefore, the probability that $X$ lies in the interval $[0.25,0.5]$ is $0.25$.\n\n:::\n\n::: {.callout-note appearance=\"simple\"}\n\n## Example 5\n\nThe **normal distribution** is a widely used example of a PDF. It is often employed to model naturally occurring phenomena such as height, weight, and other biological measurements; as well as being a central key in modelling statistics of independent and identically distributed variables. \n\nThe general PDF of the normal distribution is given by: \n\n$$\nf(x) = \\frac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\left({-\\frac{1}{2} \\left( \\frac{x - \\mu}{\\sigma} \\right)^2}\\right)\n$$\nwhere $\\mu$ is the mean and $\\sigma$ is the standard deviation. (See [Guide: Expected value, variance, standard deviation](expectedvariance.qmd) for more.) \n\nAll normal distributions are considered valid PDFs; see [Proof sheet: PMFs, PDFs, CDFs](../proofsheets/ps-pmfspdfscdfs.qmd) for more.\n\nYou will find that normal distributions share a similar shape, with the peak centered at the mean and the steepness of the curve dependent on the standard deviation. \n\n:::\n\n::: {.content-hidden when-format=\"html\"}\n\nThe standard normal distribution with a mean of $0$ and a standard deviation of $1$ is shown in @fig-pmfspdfscdfs4 below:\n\n::: {#fig-pmfspdfscdfs4}\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](pmfspdfscdfs_files/figure-docx/unnamed-chunk-4-1.png)\n:::\n:::\n\n\n\n\n\n\n\n\nPDF of a normal distribution with mean $\\mu=0$ and standard deviation $\\sigma=1$, as in Example 5.\n\n:::\n\n:::\n\n::: {.content-visible when-format=\"html\"}\n\nYou can use the interactive calculator below to explore the normal distribution by changing the mean $\\mu$ and the standard deviation $\\sigma$. This calculator not only gives you the PDF between $a$ and $b$, which is $\\mathbb{P}(a\\leq X\\leq b)$, but it also allows you to calculate the CDF for the normal distribution (see later in the guide for a definition of this.)\n\n```{shinylive-r}\n#| standalone: true\n#| viewerHeight: 700\n\nlibrary(shiny)\nlibrary(bslib)\nlibrary(ggplot2)\n\nui <- page_fluid(\n  title = \"Normal distribution calculator\",\n  \n  layout_columns(\n    col_widths = c(4, 8),\n    \n    # Left column - Inputs\n    card(\n      card_header(\"Parameters\"),\n      card_body(\n        numericInput(\"mean\", \"Mean (μ):\", value = 0),\n        numericInput(\"sd\", \"Standard deviation (σ):\", value = 1, min = 0.01),\n        hr(),\n        radioButtons(\"prob_type\", \"Probability to calculate:\",\n                    choices = list(\"P(X ≤ x)\" = \"less\", \n                                  \"P(X ≥ x)\" = \"greater\", \n                                  \"P(x ≤ X ≤ y)\" = \"between\"),\n                    selected = \"less\"),\n        conditionalPanel(\n          condition = \"input.prob_type == 'less' || input.prob_type == 'greater'\",\n          numericInput(\"x_value\", \"x value:\", value = 0)\n        ),\n        conditionalPanel(\n          condition = \"input.prob_type == 'between'\",\n          numericInput(\"x_lower\", \"Lower bound (x):\", value = -1),\n          numericInput(\"x_upper\", \"Upper bound (y):\", value = 1)\n        )\n      )\n    ),\n    \n    # Right column - Plot\n    card(\n      card_header(\"Normal distribution plot\"),\n      card_body(\n        uiOutput(\"plot_title\"),\n        plotOutput(\"distPlot\", height = \"300px\")\n      )\n    )\n  ),\n  \n  # Bottom row - Results\n  card(\n    card_header(\"Results\"),\n    card_body(\n      # Removed the LaTeX formula display\n      textOutput(\"explanation\")\n    )\n  )\n)\n\nserver <- function(input, output, session) {\n  \n  # Display the plot title with distribution parameters\n  output$plot_title <- renderUI({\n    title <- sprintf(\"N(μ = %.2f, σ = %.2f)\", input$mean, input$sd)\n    tags$h4(title, style = \"text-align: center; margin-bottom: 15px;\")\n  })\n  \n  # Calculate the probability based on user selection\n  probability <- reactive({\n    if (input$prob_type == \"less\") {\n      prob <- pnorm(input$x_value, mean = input$mean, sd = input$sd)\n      explanation <- sprintf(\"P(X ≤ %.2f) = %.4f or %.2f%%\", \n                            input$x_value, prob, prob * 100)\n      return(list(prob = prob, explanation = explanation, type = \"less\", x = input$x_value))\n      \n    } else if (input$prob_type == \"greater\") {\n      prob <- 1 - pnorm(input$x_value, mean = input$mean, sd = input$sd)\n      explanation <- sprintf(\"P(X ≥ %.2f) = %.4f or %.2f%%\", \n                            input$x_value, prob, prob * 100)\n      return(list(prob = prob, explanation = explanation, type = \"greater\", x = input$x_value))\n      \n    } else if (input$prob_type == \"between\") {\n      lower_prob <- pnorm(input$x_lower, mean = input$mean, sd = input$sd)\n      upper_prob <- pnorm(input$x_upper, mean = input$mean, sd = input$sd)\n      prob <- upper_prob - lower_prob\n      explanation <- sprintf(\"P(%.2f ≤ X ≤ %.2f) = %.4f or %.2f%%\", \n                            input$x_lower, input$x_upper, prob, prob * 100)\n      return(list(prob = prob, explanation = explanation, type = \"between\", \n                 lower = input$x_lower, upper = input$x_upper))\n    }\n  })\n  \n  # Display an explanation of the calculation\n  output$explanation <- renderText({\n    res <- probability()\n    return(res$explanation)\n  })\n  \n  # Generate the normal distribution plot\n  output$distPlot <- renderPlot({\n    # Calculate range for x-axis (covering 99.7% of the distribution)\n    x_min <- input$mean - 3.5 * input$sd\n    x_max <- input$mean + 3.5 * input$sd\n    \n    # Create data frame for plotting\n    x <- seq(x_min, x_max, length.out = 500)\n    y <- dnorm(x, mean = input$mean, sd = input$sd)\n    df <- data.frame(x = x, y = y)\n    \n    # Create base plot\n    p <- ggplot(df, aes(x = x, y = y)) +\n      geom_line() +\n      labs(x = \"X\", y = \"Density\") +\n      theme_minimal() +\n      theme(panel.grid.minor = element_blank())\n    \n    # Add bold line at X = 0\n    p <- p + geom_vline(xintercept = 0, linetype = \"solid\", color = \"black\", linewidth = 0.8)\n    \n    # Add shaded area based on selected probability type\n    res <- probability()\n    \n    if (res$type == \"less\") {\n      shade_x <- seq(x_min, res$x, length.out = 200)\n      shade_y <- dnorm(shade_x, mean = input$mean, sd = input$sd)\n      shade_df <- data.frame(x = shade_x, y = shade_y)\n      \n      p <- p + geom_area(data = shade_df, aes(x = x, y = y), fill = \"#3F6BB6\", alpha = 0.6) +\n        geom_vline(xintercept = res$x, linetype = \"dashed\", color = \"#db4315\")\n      \n    } else if (res$type == \"greater\") {\n      shade_x <- seq(res$x, x_max, length.out = 200)\n      shade_y <- dnorm(shade_x, mean = input$mean, sd = input$sd)\n      shade_df <- data.frame(x = shade_x, y = shade_y)\n      \n      p <- p + geom_area(data = shade_df, aes(x = x, y = y), fill = \"#3F6BB6\", alpha = 0.6) +\n        geom_vline(xintercept = res$x, linetype = \"dashed\", color = \"#db4315\")\n      \n    } else if (res$type == \"between\") {\n      shade_x <- seq(res$lower, res$upper, length.out = 200)\n      shade_y <- dnorm(shade_x, mean = input$mean, sd = input$sd)\n      shade_df <- data.frame(x = shade_x, y = shade_y)\n      \n      p <- p + geom_area(data = shade_df, aes(x = x, y = y), fill = \"#3F6BB6\", alpha = 0.6) +\n        geom_vline(xintercept = res$lower, linetype = \"dashed\", color = \"#db4315\") +\n        geom_vline(xintercept = res$upper, linetype = \"dashed\", color = \"#db4315\")\n    }\n    \n    return(p)\n  })\n}\n\nshinyApp(ui = ui, server = server)\n```\n\n:::\n\n# Key differences between PMFs and PDFs\n\n| **Probability mass function (PMF)** | **Probability density function (PDF)** |\n|----|----|\n| Finds the probabilities of **discrete random variables** | Finds the probabilities of **continuous random variables** |\n| Probabilities range from **0 to 1** for each exact outcome | Probabilities are calculated over intervals as the probability of an exact outcome is always **0**. |\n| Provides likelihood that $X$ occurs at an **exact value** | Provides likelihood that $X$ lies within an **interval** |\n| **Sum** of probabilities equals 1 | **Integral** over entire domain equals 1 |\n\nTable 3: Table comparing the key differences between PMFs and PDFs.\n\n# What is a cumulative distribution function (CDF)?\n\nAnother key concept in the area of probability distributions is the **cumulative distribution function (CDF)**. A CDF returns the probability that a random variable $X$ is **less than or equal to** a specific value $x$. CDFs can be derived from both probability mass functions (PMFs) for discrete random variables and probability density functions (PDFs) for continuous random variables.\n\n::: {.callout-note}\n\n## Definition of a CDF\n\nA **cumulative distribution function** or **CDF** is a function $F(x)$ that returns the probability that the random $X$ is less than or equal to a variable $x$. This probability is written by $\\mathbb{P}(X\\leq x)$.\n\n- For a discrete random variable with a PMF $p(x)$, the CDF is given by: $$F(x) = \\mathbb{P}(X \\leq x) = \\sum_{y \\leq x} p(y)$$ where $y$ is an outcome 'less than or equal to' $x$, given the appropriate order on the set of all possible outcomes. \n- For a continuous random variable with a PDF $f(x)$, the CDF is given by: \n$$F(x) = \\mathbb{P}(X \\leq x) = \\int_{-\\infty}^{x} f(y) \\, \\textrm{d}y$$ where $y$ is a 'dummy variable' allowing for the computation of this integral.\n:::\n\n::: {.callout-warning}\n\nCDFs are always **non-decreasing**. This is because they deal with cumulative probabilities, which represent the total probability up to a certain point. Since the probability of an event can only increase or remain the same as more outcomes are considered, the probability of a random variable being less than or equal to any value $x$ is always non-decreasing as $x$ increases.\n\n:::\n\n::: {.callout-note appearance=\"simple\"}\n## Example 6\n\nSuppose you roll a fair six-sided die, as in Example 1. Since this scenario involves a PMF, the cumulative distribution function (CDF) can be derived using the following method. \n\nTo find the probability of rolling a three or lower, add the probabilities of rolling each number less than or equal to three: \n$$F(3) = \\mathbb{P}(X \\leq 3) = \\sum_{x \\leq 3} p(x) = \\underbrace{\\frac{1}{6}}_{\\mathbb{P}(X=1)} + \\underbrace{\\frac{1}{6}}_{\\mathbb{P}(X=2)} + \\underbrace{\\frac{1}{6}}_{\\mathbb{P}(X=3)} = \\frac{3}{6} = \\frac{1}{2}$$\n\nTherefore, the probability of rolling a three or lower is $50\\%$.\n\nYou can extend this working to show that the entire CDF is given by:\n\n| $x$ | 1 | 2 | 3 | 4 | 5 | 6 |\n|--------|----|----|----|----|----|----|\n| $\\mathbb{P}(X \\leq x)$ | $\\dfrac{1}{6}$ | $\\dfrac{1}{3}$ | $\\dfrac{1}{2}$ | $\\dfrac{2}{3}$ | $\\dfrac{5}{6}$ | 1 |\n\nTable 4: CDF for rolling a fair six-sided die, as in Example 6.\n\n:::\n\n::: {.callout-note icon=\"true\"}\n## Example 7\n\nImagine you flip a coin twice, like in Example 2, and let $X$ be the random variable corresponding to the number of heads. Since this scenario represents a discrete random variable with a PMF, the CDF can be derived by summing the probabilities of outcomes less than or equal to $x$, similar to the previous example:\n\n| $x$           | 0    | 1    | 2   |\n|--------|----|----|----|\n| $\\mathbb{P}(X \\leq x)$ | 0.25 | 0.75 | 1   |\n\nTable 5: CDF for flipping a fair coin twice, as in Example 7.\n\n\nTo find the probability that $X$ is strictly greater than $x$, you can subtract the correlating value in the CDF from the total probability.\n\nFor example, to find the probability that $X$ is greater than $1$: $$\\mathbb{P}(X > 1) = 1 - F(1) = 1 - \\mathbb{P}(X \\leq 1) = 1 - 0.75 = 0.25$$\n\nTherefore, the probability that $X$ is greater than $1$ is $0.25$.\n:::\n\n::: {.callout-note appearance=\"simple\"}\n## Example 8\n\nConsider a continuous random variable $X$ uniformly distributed between $0$ and $1$, which you saw in Example 4. The PDF of $X$ was given by:\n\n$$f(x) =\\begin{cases}1 & \\textsf{if } 0 \\leq x \\leq 1 \\\\0 & \\textsf{otherwise} \\end{cases}$$\n\nTo find the probability that $X$ is less than or equal to $0.5$, you use the formula from the definition of the CDF:\n\n$$F(0.5) = \\mathbb{P}(X \\leq 0.5) = \\int_{-\\infty}^{0.5} f(y) \\, \\textrm{d}y$$\nYou can then use properties of integration by splitting the limits of integration to match the definition of the PDF. This allows you to work out the value of the integral:\n\n$$\\int_{-\\infty}^{0.5} f(y) \\, dy = \\int_{-\\infty}^{0} f(y) \\, dy + \\int_{0}^{0.5} f(y) \\, dy = \\int_{-\\infty}^{0} 0 \\, dy + \\int_{0}^{0.5} 1 \\, dy = 0 + [x]_0^{0.5} = 0.5$$\n\nSo the probability of $X$ being less than or equal to $0.5$ is $50\\%$.\n\nOn the other hand, to find the probability that $X$ is greater than $0.5$, you can subtract the CDF value at $0.5$ (which is $F(0.5)$ from the total probability $1$: \n$$\\mathbb{P}(X>0.5) = 1 − F(0.5) = 1 − 0.5 = 0.5$$\nSo the probability that $X$ is greater than $0.5$ is also $50\\%$.\n:::\n\n# Quick check problems\n\n::: {.content-visible when-format=\"html\"}\n\n::: {.webex-check .webex-box data-topic=\"PPC1\"}\n\nIn the following questions, please enter your answers as decimal numbers.\n\n1. Are the following statements true or false?\n\n(a) PMFs are used for discrete random variables: TRUE / FALSE\n\n(b) PDFs assign probabilities to individual outcomes: TRUE / FALSE\n\n(c) The CDF can decrease as the random variable increases: TRUE / FALSE\n\n2. A fair 4-sided die is rolled.\n\n(a) What type of probability distribution function would you use for this scenario? \n\n* (A) PMF  \n* (B) PDF  \n* (C) CDF  \n\n\n\n(b) What is the probability of rolling a 4? ____\n\n(c) What is the probability of rolling a number less than or equal to a 2? ___\n\n(d) What is the probability of rolling an even number? ___\n\n3. A continuous random variable $X$ is uniformly distributed on $[0,4]$.\n\n(a) What probability distribution function would you use for this scenario? \n\n* (A) PMF  \n* (B) PDF  \n* (C) CDF  \n\n\n\n(b) What is the value of $f(x)$ over the interval $[0, 4]$? ____\n\n(c) What is $\\mathbb{P}(1 \\leq X \\leq 3)$? ___\n\n(d) What is the probability $\\mathbb{P}(X \\leq 2)$? ___ \n\n:::\n\n:::\n\n::: {.content-hidden when-format=\"html\"}\n\n1. Are the following statements true or false?\n\n(a) PMFs are used for discrete random variables.\n\n(b) PDFs assign probabilities to individual outcomes.\n\n(c) The CDF can decrease as the random variable increases.\n\n2. A fair 4-sided die is rolled.\n\n(a) What type of probability distribution function would you use for this scenario?\n\n(b) What is the probability of rolling a 4?\n\n(c) What is the probability of rolling a number less than or equal to a 2?\n\n(d) What is the probability of rolling an even number?\n\n3. A continuous random variable $X$ is uniformly distributed on $[0,4]$.\n\n(a) What probability distribution function would you use for this scenario?\n\n(b) What is the value of $f(x)$ over the interval $[0, 4]$? \n\n(c) What is $\\mathbb{P}(1 \\leq X \\leq 3)$? \n\n(d) What is the probability $\\mathbb{P}(X \\leq 2)$?\n\n:::\n\n# Further reading {-}\n\n[For more questions on the subject, please go to Questions: PMFs, PDFs, and CDFs.](../questions/qs-pmfspdfscdfs.qmd)\n\n[For more on why some PMFs and PDFs are valid, please go to Proof sheet: PMFs, PDFs, CDFs.](../proofsheets/ps-pmfspdfscdfs.qmd)\n\nFor more on probability distributions see [Overview: Probability distributions.]\n\n## Version history and licensing {-}\n\nv1.0: initial version created 12/24 by Sophie Chowgule as part of a University of St Andrews VIP project.\n\n  - v1.1: interactive elements added by tdhc 05/24. \n  \n[This work is licensed under CC BY-NC-SA 4.0.](https://creativecommons.org/licenses/by-nc-sa/4.0/?ref=chooser-v1)\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}